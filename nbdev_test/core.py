# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['get_data', 'make_experiment', 'model']

# Cell
import numpy as np
from sklearn import datasets
import matplotlib.pyplot as plt


def get_data(n_samples = 1000, n_outliers = 100):
    ''' Generate nonlinear data with outliers.
        Don't hesitate to change the generation parameters, method and data itself! Observe, how it changes results
    '''
    X, y = datasets.make_regression(n_samples=n_samples, n_features=1,
                                          n_informative=1, noise=25,
                                          coef=False, random_state=1110)



    # Replace first N samples with outliers

    X[:n_outliers] = np.random.normal(size=(n_outliers, 1))
    y[:n_outliers] = 100 * np.random.normal(size=n_outliers)

    # Add non-linearity to data

    y = y+100*X.T[0]*np.sin(X.T[0])

    # Scale data to put in range [0,1] for stability.
    # Check results if ignore it.
    # See also sklearn User Guide (https://scikit-learn.org/stable/modules/preprocessing.html#scaling-features-to-a-range) and try another tools (Standartization, Normalization)
    X = (X - X.min())/(X.max()-X.min())
    y = (y - y.min())/(y.max()-y.min())
    return X,y

X,y = get_data()
assert len(X)==len(y)
plt.plot(X, y, 'o', label = 'Data')
plt.legend()

# Cell

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

import mlflow
import mlflow.sklearn

def make_experiment(X, y, n = 5):
    with mlflow.start_run() as run:
        experiment = 'polynomial regression'
        mlflow.set_experiment(experiment)
        mlflow.log_param("degree", n)
        run_id = run.info.run_id
        print(run.info)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

        polynomial_features = PolynomialFeatures(degree = n) # create instance of transformer
        regression = LinearRegression() # create instance of model

        # make pipeline as list of pairs (<stage name>, <stage object>):
        pipeline = Pipeline([("polynomial_features", polynomial_features), # augment data
                           ("linear_regression", regression)]) # apply linear regression

        # from now we can treat pipeline as a single model, applying all stages when using fit() and predict()
        pipeline.fit(X_train, y_train)
        score = pipeline.score(X_test, y_test)
        print("Score: %s" % score)
        mlflow.log_metric("score", score)
        mlflow.sklearn.log_model(pipeline, "model")
        print("Model saved in run %s" % mlflow.active_run().info.run_uuid)
        return pipeline
model = make_experiment(X,y)
#assert len(model.predict(X))==len(y)